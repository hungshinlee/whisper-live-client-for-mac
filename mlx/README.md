# MLX Whisper å®¢æˆ¶ç«¯

ä½¿ç”¨ Apple Silicon GPU åŠ é€Ÿçš„å³æ™‚èªéŸ³è½‰æ–‡å­—å·¥å…·ã€‚

## å„ªå‹¢

| ç‰¹æ€§ | WhisperLive (faster-whisper) | MLX Whisper |
|------|------------------------------|-------------|
| Apple GPU | âŒ ä¸æ”¯æ´ | âœ… æ”¯æ´ |
| é‹ç®—è£ç½® | CPU only | Apple Silicon GPU |
| æ¶æ§‹ | Client-Server | å–®ä¸€ç¨‹å¼ |

## è¨­ç½®æ­¥é©Ÿ

### 1. å®‰è£ç³»çµ±ä¾è³´

```bash
brew install ffmpeg portaudio
```

### 2. å»ºç«‹è™›æ“¬ç’°å¢ƒ

```bash
cd /Users/winston/Projects/whisper-live-client/mlx
uv venv
uv pip install mlx-whisper pyaudio numpy
```

---

## ğŸ¤ å³æ™‚èªéŸ³è¾¨è­˜

å¯ä»¥ç›´æ¥ä½¿ç”¨ HuggingFace ä¸Šçš„ MLX æ¨¡å‹ï¼ˆæœƒè‡ªå‹•ä¸‹è¼‰ï¼‰ï¼Œæˆ–ä½¿ç”¨è‡ªè¡Œè½‰æ›çš„æ¨¡å‹ã€‚

### ä½¿ç”¨ HuggingFace æ¨¡å‹ï¼ˆè‡ªå‹•ä¸‹è¼‰ï¼Œæœ€ç°¡å–®ï¼‰

ä¸éœ€è¦è½‰æ›ï¼Œç›´æ¥ä½¿ç”¨ï¼š

```bash
# ç´”è½‰éŒ„ï¼ˆä½¿ç”¨ whisper-large-v3ï¼‰
uv run python transcribe_only.py

# ç¿»è­¯æˆè‹±æ–‡
uv run python transcribe.py
```

### ä½¿ç”¨æœ¬åœ°è½‰æ›çš„æ¨¡å‹

å¦‚æœä½ å·²ç¶“è½‰æ›äº†è‡ªè¨‚æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ `realtime.py`ï¼š

```bash
# åŸºæœ¬ä½¿ç”¨ï¼ˆè‡ªå‹•åµæ¸¬èªè¨€ï¼Œç´”è½‰éŒ„ï¼‰
uv run python realtime.py

# åˆ—å‡ºå¯ç”¨æ¨¡å‹
uv run python realtime.py --list

# æŒ‡å®šæ¨¡å‹
uv run python realtime.py --model whisper-large-v2-taiwanese-hakka-v1-mlx

# ç¿»è­¯æˆè‹±æ–‡
uv run python realtime.py --task translate

# æŒ‡å®šèªè¨€ç‚ºä¸­æ–‡
uv run python realtime.py --language zh

# çµ„åˆä½¿ç”¨
uv run python realtime.py -m whisper-large-v2-taiwanese-hakka-v1-mlx -l zh -t transcribe
```

### åƒæ•¸èªªæ˜

| åƒæ•¸ | ç°¡å¯« | èªªæ˜ | é è¨­å€¼ |
|------|------|------|--------|
| `--model` | `-m` | æ¨¡å‹åç¨±æˆ–è·¯å¾‘ | ç¬¬ä¸€å€‹å¯ç”¨æ¨¡å‹ |
| `--task` | `-t` | `transcribe`ï¼ˆè½‰éŒ„ï¼‰æˆ– `translate`ï¼ˆç¿»è­¯æˆè‹±æ–‡ï¼‰| `transcribe` |
| `--language` | `-l` | èªè¨€ä»£ç¢¼ï¼ˆå¦‚ zh, en, jaï¼‰| è‡ªå‹•åµæ¸¬ |
| `--list` | | åˆ—å‡ºå¯ç”¨æ¨¡å‹ | |

---

## æ¨¡å‹é¸æ“‡å»ºè­°

âš ï¸ **æ•ˆèƒ½æç¤ºï¼š** å¦‚æœä½ çš„ Mac æ™¶ç‰‡ä¸æ˜¯ M4ï¼Œå»ºè­°ä½¿ç”¨ `medium` æˆ–æ›´å°çš„æ¨¡å‹ï¼Œä»¥ç²å¾—æ›´æµæš¢çš„é«”é©—ã€‚

| æ™¶ç‰‡ | å»ºè­°æ¨¡å‹ | èªªæ˜ |
|------|----------|------|
| M4 / M4 Pro / M4 Max | `large-v3` | æœ€ä½³å“è³ªï¼Œé€Ÿåº¦å¿« |
| M3 / M3 Pro / M3 Max | `large-v3` æˆ– `medium` | large å¯èƒ½ç¨æ…¢ |
| M2 / M2 Pro / M2 Max | `medium` æˆ– `small` | å¹³è¡¡å“è³ªèˆ‡é€Ÿåº¦ |
| M1 / M1 Pro / M1 Max | `small` æˆ– `base` | ç¢ºä¿æµæš¢é«”é©— |

### å¯ç”¨æ¨¡å‹

âš ï¸ **æ³¨æ„ï¼šturbo ç‰ˆæœ¬ä¸æ”¯æ´ç¿»è­¯åŠŸèƒ½ï¼**

| æ¨¡å‹ | å¤§å° | ç¿»è­¯æ”¯æ´ | å»ºè­°æ™¶ç‰‡ |
|------|------|----------|----------|
| `mlx-community/whisper-large-v3-mlx` | ~3 GB | âœ… æ”¯æ´ | M3/M4 |
| `mlx-community/whisper-large-v3-turbo` | ~1.6 GB | âŒ ä¸æ”¯æ´ | M2/M3/M4 |
| `mlx-community/whisper-medium-mlx` | ~1.5 GB | âœ… æ”¯æ´ | M1/M2/M3/M4 |
| `mlx-community/whisper-small-mlx` | ~488 MB | âœ… æ”¯æ´ | å…¨éƒ¨ |
| `mlx-community/whisper-base-mlx` | ~145 MB | âœ… æ”¯æ´ | å…¨éƒ¨ |
| `mlx-community/whisper-tiny-mlx` | ~75 MB | âœ… æ”¯æ´ | å…¨éƒ¨ |

å¦‚éœ€ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼Œå¯ä»¥ä¿®æ”¹ `transcribe.py` æˆ– `transcribe_only.py` ä¸­çš„ `MODEL_NAME`ï¼š

```python
# ä¾‹å¦‚æ”¹ç”¨ medium æ¨¡å‹
MODEL_NAME = "mlx-community/whisper-medium-mlx"
```

---

## ğŸ–¥ï¸ æµ®å‹•å­—å¹•è¦–çª—ï¼ˆç°¡å ±ç”¨ï¼‰

é©ç”¨æ–¼å…¨è¢å¹•ç°¡å ±æ™‚å³æ™‚é¡¯ç¤ºå­—å¹•ã€‚

```bash
cd subtitle
uv pip install pyobjc-framework-Cocoa

# åŸºæœ¬ä½¿ç”¨
uv run python subtitle.py

# ç¿»è­¯æˆè‹±æ–‡
uv run python subtitle.py --task translate

# æŒ‡å®šæ¨¡å‹å’Œèªè¨€
uv run python subtitle.py -m whisper-large-v2-taiwanese-hakka-v1-mlx -l zh
```

è©³ç´°èªªæ˜è«‹åƒè€ƒ [subtitle/README.md](subtitle/README.md)ã€‚

---

## è½‰æ›è‡ªè¨‚æ¨¡å‹ï¼ˆå¯é¸ï¼‰

å¦‚æœéœ€è¦ä½¿ç”¨ç‰¹å®šèªè¨€çš„å¾®èª¿æ¨¡å‹ï¼ˆå¦‚è‡ºç£å®¢èªï¼‰ï¼Œå¯ä»¥å°‡ HuggingFace ä¸Šçš„ Whisper æ¨¡å‹è½‰æ›ç‚º MLX æ ¼å¼ã€‚

```bash
cd convert

# è½‰æ›æ¨¡å‹
./convert.sh <hf-repo>

# ç¯„ä¾‹ï¼šè‡ºç£å®¢èªæ¨¡å‹
./convert.sh formospeech/whisper-large-v2-taiwanese-hakka-v1

# ç¯„ä¾‹ï¼šOpenAI å®˜æ–¹æ¨¡å‹
./convert.sh openai/whisper-large-v3

# å¼·åˆ¶é‡æ–°è½‰æ›
./convert.sh formospeech/whisper-large-v2-taiwanese-hakka-v1 --force
```

è½‰æ›å¾Œçš„æ¨¡å‹å­˜æ”¾åœ¨ `models/` ç›®éŒ„ã€‚

è©³ç´°èªªæ˜è«‹åƒè€ƒ [convert/README.md](convert/README.md)ã€‚

---

## ç¢ºèª GPU ä½¿ç”¨

åŸ·è¡Œæ™‚æ‰“é–‹ã€Œæ´»å‹•ç›£è¦–å™¨ã€â†’ã€ŒGPUã€åˆ†é ï¼Œæ‡‰è©²æœƒçœ‹åˆ° Python æ­£åœ¨ä½¿ç”¨ GPUã€‚

## èˆ‡ WhisperLive çš„å·®ç•°

- **MLX Whisper**ï¼šå–®ä¸€ç¨‹å¼ï¼Œä½¿ç”¨ Apple GPUï¼Œèªªå®Œä¸€å¥è©±å¾Œæ‰è¾¨è­˜
- **WhisperLive**ï¼šClient-Server æ¶æ§‹ï¼Œä½¿ç”¨ CPUï¼Œå¯ä»¥å³æ™‚ä¸²æµé¡¯ç¤º

å¦‚æœéœ€è¦ã€Œé‚Šèªªé‚Šé¡¯ç¤ºã€çš„å³æ™‚æ•ˆæœï¼Œè«‹ä½¿ç”¨ä¸Šå±¤ç›®éŒ„çš„ WhisperLive ç‰ˆæœ¬ã€‚

---

## ç›®éŒ„çµæ§‹

```
mlx/
â”œâ”€â”€ transcribe.py         # ç¿»è­¯ï¼ˆHF æ¨¡å‹è‡ªå‹•ä¸‹è¼‰ï¼‰
â”œâ”€â”€ transcribe_only.py    # è½‰éŒ„ï¼ˆHF æ¨¡å‹è‡ªå‹•ä¸‹è¼‰ï¼‰
â”œâ”€â”€ realtime.py           # ğŸ¤ å³æ™‚èªéŸ³è¾¨è­˜ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
â”œâ”€â”€ convert/              # æ¨¡å‹è½‰æ›å·¥å…·
â”‚   â”œâ”€â”€ convert.sh
â”‚   â”œâ”€â”€ convert.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ models/               # è½‰æ›å¾Œçš„æ¨¡å‹
â”‚   â””â”€â”€ {model-name}-mlx/
â””â”€â”€ subtitle/             # ğŸ–¥ï¸ æµ®å‹•å­—å¹•è¦–çª—
    â”œâ”€â”€ subtitle.py
    â””â”€â”€ README.md
```
