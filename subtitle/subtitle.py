"""
å³æ™‚å­—å¹•æµ®å‹•è¦–çª— - macOS åŸç”Ÿç‰ˆæœ¬
ä½¿ç”¨ PyObjC ç¢ºä¿åœ¨å…¨è¢å¹•ç°¡å ±ä¸Šæ–¹ä¹Ÿèƒ½é¡¯ç¤º

ä½¿ç”¨æ–¹å¼ï¼ˆå¾å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œï¼‰:
  # ä½¿ç”¨é è¨­æ¨¡å‹
  uv run python subtitle/subtitle.py
  
  # æŒ‡å®šæ¨¡å‹
  uv run python subtitle/subtitle.py --model mlx-community/whisper-medium-mlx
  
  # ç¿»è­¯æˆè‹±æ–‡
  uv run python subtitle/subtitle.py --task translate
  
  # æŒ‡å®šèªè¨€
  uv run python subtitle/subtitle.py --language zh
  
  # åˆ—å‡ºå¯ç”¨æ¨¡å‹
  uv run python subtitle/subtitle.py --list
"""
import argparse
import signal
import sys
import threading
import queue
import time
from collections import deque
import numpy as np
import pyaudio
import mlx_whisper
from pathlib import Path
from opencc import OpenCC

# åŠ å…¥çˆ¶ç›®éŒ„åˆ° path ä»¥ä¾¿ import vad
sys.path.insert(0, str(Path(__file__).parent.parent))
from vad import SileroVAD, VADConfig

import AppKit
from AppKit import (
    NSApplication, NSWindow, NSTextField, NSColor, NSFont,
    NSWindowStyleMaskBorderless, NSBackingStoreBuffered,
    NSScreenSaverWindowLevel,
    NSMakeRect, NSScreen,
    NSTextAlignmentCenter,
    NSApplicationActivationPolicyAccessory
)
from PyObjCTools import AppHelper

# ===========================================
# ğŸ“ è¦–çª—è¨­å®šï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ===========================================
WINDOW_WIDTH_RATIO = 0.8      # è¦–çª—å¯¬åº¦ä½”è¢å¹•æ¯”ä¾‹ (0.0 ~ 1.0)
WINDOW_BOTTOM_MARGIN = 50     # è¦–çª—è·é›¢è¢å¹•åº•éƒ¨çš„è·é›¢ (åƒç´ )
WINDOW_OPACITY = 0.85         # è¦–çª—é€æ˜åº¦ (0.0 ~ 1.0ï¼Œ1.0 ç‚ºä¸é€æ˜)

# ===========================================
# ğŸ”¤ æ–‡å­—è¨­å®šï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ===========================================
FONT_SIZE = 36                # å­—é«”å¤§å° (åƒç´ )
FONT_NAME = None              # å­—é«”åç¨±ï¼ŒNone ç‚ºç³»çµ±é è¨­ç²—é«”
MAX_LINES = 3                 # é¡¯ç¤ºè¡Œæ•¸ï¼ˆæœ€æ–°çš„æ–‡å­—åœ¨æœ€ä¸‹é¢ï¼‰
LINE_HEIGHT = 1.3             # è¡Œé«˜å€ç‡

# ===========================================
# ğŸ¨ é¡è‰²è¨­å®šï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ===========================================
BACKGROUND_COLOR = (0.1, 0.1, 0.1)  # æ·±ç°è‰²
TEXT_COLOR = "white"          # white / yellow / green / cyan

# ===========================================
# ğŸ™ï¸ éŒ„éŸ³è¨­å®š
# ===========================================
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 512  # Silero VAD éœ€è¦ç‰¹å®šå¤§å°

# ===========================================
# é è¨­è¨­å®š
# ===========================================
DEFAULT_HF_MODEL = "mlx-community/whisper-large-v3-mlx"
MODELS_DIR = Path(__file__).parent.parent / "models"

# ===========================================
# ç°¡ç¹è½‰æ›ï¼ˆè‡ºç£ç¹é«”ï¼‰
# ===========================================
# s2twp: ç°¡é«”ä¸­æ–‡ -> ç¹é«”ä¸­æ–‡ï¼ˆå°ç£ï¼‰ï¼ŒåŒ…å«å¸¸ç”¨è©è½‰æ›ï¼ˆå¦‚ã€Œé¼ æ¨™ã€â†’ã€Œæ»‘é¼ ã€ï¼‰
cc = OpenCC('s2twp')

# å…¨åŸŸè®Šæ•¸
running = True
model = None
task = "transcribe"
language = None
vad_config = None
convert_tw = False


def should_convert_to_tw(model_path: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦éœ€è¦è½‰æ›æˆè‡ºç£ç¹é«”"""
    # mlx-community/whisper* æ¨¡å‹è¼¸å‡ºå¯èƒ½æ˜¯ç°¡é«”ä¸­æ–‡ï¼Œéœ€è¦è½‰æ›
    return model_path.startswith("mlx-community/whisper")


def convert_to_tw(text: str) -> str:
    """å°‡æ–‡å­—è½‰æ›æˆè‡ºç£ç¹é«”ä¸­æ–‡"""
    return cc.convert(text)


def list_local_models() -> list[str]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æœ¬åœ°æ¨¡å‹"""
    if not MODELS_DIR.exists():
        return []
    
    models = []
    for path in MODELS_DIR.iterdir():
        if path.is_dir():
            config_file = path / "config.json"
            weights_file = path / "weights.npz"
            if config_file.exists() and weights_file.exists():
                models.append(path.name)
    
    return sorted(models)


def resolve_model(model_name: str | None) -> str:
    """è§£ææ¨¡å‹åç¨±ï¼Œè¿”å›å¯ç”¨çš„æ¨¡å‹è·¯å¾‘æˆ– HF repo"""
    
    if model_name is None:
        local_models = list_local_models()
        if local_models:
            return str(MODELS_DIR / local_models[0])
        return DEFAULT_HF_MODEL
    
    if "/" in model_name:
        return model_name
    
    model_path = MODELS_DIR / model_name
    if model_path.exists():
        return str(model_path)
    
    if not model_name.endswith("-mlx"):
        model_path = MODELS_DIR / f"{model_name}-mlx"
        if model_path.exists():
            return str(model_path)
    
    return f"mlx-community/{model_name}"


def get_text_color():
    """å–å¾—æ–‡å­—é¡è‰²"""
    colors = {
        "white": NSColor.whiteColor(),
        "yellow": NSColor.yellowColor(),
        "green": NSColor.greenColor(),
        "cyan": NSColor.cyanColor(),
    }
    return colors.get(TEXT_COLOR, NSColor.whiteColor())


class SubtitleWindow:
    def __init__(self):
        screen = NSScreen.mainScreen()
        screen_frame = screen.frame()
        screen_width = screen_frame.size.width
        
        window_width = screen_width * WINDOW_WIDTH_RATIO
        # æ ¹æ“šè¡Œæ•¸è¨ˆç®—è¦–çª—é«˜åº¦
        line_pixel_height = FONT_SIZE * LINE_HEIGHT
        window_height = int(line_pixel_height * MAX_LINES + 30)  # åŠ ä¸Š padding
        
        x = (screen_width - window_width) / 2
        y = WINDOW_BOTTOM_MARGIN
        
        self.window = NSWindow.alloc().initWithContentRect_styleMask_backing_defer_(
            NSMakeRect(x, y, window_width, window_height),
            NSWindowStyleMaskBorderless,
            NSBackingStoreBuffered,
            False
        )
        
        self.window.setLevel_(NSScreenSaverWindowLevel)
        self.window.setOpaque_(False)
        self.window.setBackgroundColor_(
            NSColor.colorWithCalibratedRed_green_blue_alpha_(
                BACKGROUND_COLOR[0], 
                BACKGROUND_COLOR[1], 
                BACKGROUND_COLOR[2], 
                WINDOW_OPACITY
            )
        )
        self.window.setHasShadow_(True)
        self.window.setMovableByWindowBackground_(True)
        self.window.setCollectionBehavior_(
            AppKit.NSWindowCollectionBehaviorCanJoinAllSpaces |
            AppKit.NSWindowCollectionBehaviorFullScreenAuxiliary
        )
        
        content_view = self.window.contentView()
        self.label = NSTextField.alloc().initWithFrame_(
            NSMakeRect(20, 10, window_width - 40, window_height - 20)
        )
        self.label.setStringValue_("ğŸ¤ ç­‰å¾…èªªè©±...")
        
        if FONT_NAME:
            font = NSFont.fontWithName_size_(FONT_NAME, FONT_SIZE)
            if font is None:
                font = NSFont.boldSystemFontOfSize_(FONT_SIZE)
        else:
            font = NSFont.boldSystemFontOfSize_(FONT_SIZE)
        self.label.setFont_(font)
        
        self.label.setTextColor_(get_text_color())
        self.label.setBackgroundColor_(NSColor.clearColor())
        self.label.setBezeled_(False)
        self.label.setEditable_(False)
        self.label.setSelectable_(False)
        self.label.setAlignment_(NSTextAlignmentCenter)
        
        # è¨­å®šå¤šè¡Œé¡¯ç¤º
        self.label.setMaximumNumberOfLines_(MAX_LINES)
        
        content_view.addSubview_(self.label)
        self.window.makeKeyAndOrderFront_(None)
        
        # æ­·å²æ–‡å­—è¨˜éŒ„
        self.text_history = deque(maxlen=MAX_LINES)
    
    def add_text(self, text):
        """æ–°å¢ä¸€è¡Œæ–‡å­—ï¼Œä¸¦æ›´æ–°é¡¯ç¤º"""
        self.text_history.append(text)
        combined_text = "\n".join(self.text_history)
        self._update_label(combined_text)
    
    def update_text(self, text):
        """æ›´æ–°å­—å¹•æ–‡å­—ï¼ˆåŸ·è¡Œç·’å®‰å…¨ï¼‰ï¼Œç”¨æ–¼ç‹€æ…‹è¨Šæ¯"""
        self._update_label(text)
    
    def _update_label(self, text):
        """å…§éƒ¨æ–¹æ³•ï¼šæ›´æ–° label æ–‡å­—"""
        def update():
            self.label.setStringValue_(text)
        AppHelper.callAfter(update)
    
    def close(self):
        def do_close():
            self.window.close()
            AppHelper.stopEventLoop()
        AppHelper.callAfter(do_close)


def transcribe_audio(audio_data: bytes) -> str:
    global model, task, language, convert_tw
    
    audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
    
    kwargs = {
        "path_or_hf_repo": model,
        "task": task,
    }
    
    if language:
        kwargs["language"] = language
    
    result = mlx_whisper.transcribe(audio_np, **kwargs)
    text = result["text"].strip()
    
    # è½‰æ›æˆè‡ºç£ç¹é«”
    if convert_tw and text:
        text = convert_to_tw(text)
    
    return text


# å»ºç«‹ç·šç¨‹å®‰å…¨çš„ä½‡åˆ—ï¼Œç”¨æ–¼å­˜æ”¾å¾…è¾¨è­˜çš„éŸ³è¨Šè³‡æ–™
transcription_queue = queue.Queue()

def transcription_thread(subtitle_window):
    """
    æ¶ˆè²»è€…åŸ·è¡Œç·’ï¼šå¾ä½‡åˆ—å–å‡ºéŸ³è¨Šä¸¦é€²è¡Œè¾¨è­˜
    é€™æ¨£åšå¯ä»¥ç¢ºä¿éŒ„éŸ³ä¸æœƒå› ç‚ºè¾¨è­˜é€Ÿåº¦æ…¢è€Œä¸­æ–·ï¼ˆé¿å…æ¼å­—ï¼‰
    """
    global running, model, task, language, convert_tw
    
    print("ğŸš€ è¾¨è­˜åŸ·è¡Œç·’å·²å•Ÿå‹•")
    
    # é ç†±æ¨¡å‹ (ç¢ºä¿æ¨¡å‹è¼‰å…¥è¨˜æ†¶é«”)
    print("â³ æ­£åœ¨é ç†±æ¨¡å‹...")
    try:
        dummy = np.zeros(RATE, dtype=np.float32)
        warmup_kwargs = {"path_or_hf_repo": model, "task": task}
        if language:
            warmup_kwargs["language"] = language
        mlx_whisper.transcribe(dummy, **warmup_kwargs)
        print("âœ… æ¨¡å‹é ç†±å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹é ç†±å¤±æ•—: {e}")
    
    while running:
        try:
            # å¾ä½‡åˆ—å–å¾—éŸ³è¨Šï¼Œtimeout è¨­ç‚º 0.5 ç§’ä»¥ä¾¿èƒ½å®šæœŸæª¢æŸ¥ running ç‹€æ…‹
            audio_data = transcription_queue.get(timeout=0.5)
        except queue.Empty:
            continue
            
        # åƒ…åœ¨çµ‚ç«¯æ©Ÿé¡¯ç¤ºæ’éšŠç‹€æ³ï¼Œä¸å½±éŸ¿å­—å¹•è¦–çª—æ»¾å‹•
        q_size = transcription_queue.qsize()
        if q_size > 0:
            print(f"â³ ä½‡åˆ—å †ç©: {q_size} å¥")
        
        try:
            text = transcribe_audio(audio_data)
            if text and running:
                subtitle_window.add_text(text)
            elif not text and running:
                # å¦‚æœè¾¨è­˜å‡ºç©ºå­—ä¸²ï¼ˆä¾‹å¦‚åªæœ‰é›œè¨Šï¼‰ï¼Œæ¢å¾©é¡¯ç¤ºæ­·å²è¨Šæ¯
                # é€™è£¡ç°¡å–®é‡ç¹ªæœ€å¾Œçš„ç‹€æ…‹ï¼Œæˆ–è€…ä¾é  add_text ä¾†è™•ç†
                # ç›®å‰ add_text æœƒé‡ç¹ªæ•´å€‹æ­·å²ï¼Œæ‰€ä»¥æˆ‘å€‘æ‰‹å‹•è§¸ç™¼ä¸€æ¬¡é‡ç¹ªæ­·å²
                combined_text = "\n".join(subtitle_window.text_history)
                # å¦‚æœæ²’æœ‰æ­·å²è³‡æ–™ï¼Œå°±é¡¯ç¤ºç­‰å¾…ä¸­
                if not combined_text:
                    combined_text = "ğŸ¤ ç­‰å¾…èªªè©±..."
                subtitle_window._update_label(combined_text)
                
        except Exception as e:
            print(f"è¾¨è­˜éŒ¯èª¤: {e}")
            subtitle_window.update_text(f"éŒ¯èª¤: {str(e)}")
        
        finally:
            transcription_queue.task_done()


def capture_thread(subtitle_window):
    """
    ç”Ÿç”¢è€…åŸ·è¡Œç·’ï¼šå°ˆæ³¨æ–¼éŒ„éŸ³å’Œ VAD åµæ¸¬
    å°‡åµæ¸¬åˆ°çš„èªéŸ³ç‰‡æ®µæ”¾å…¥ä½‡åˆ—ï¼Œçµ•ä¸é˜»å¡
    """
    global running, model, task, language, vad_config
    
    audio = pyaudio.PyAudio()
    stream = audio.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK
    )
    
    # å»ºç«‹ VAD
    vad = SileroVAD(vad_config)
    
    subtitle_window.update_text("ğŸ¤ æº–å‚™å°±ç·’ï¼Œå¯éš¨æ™‚èªªè©± (æ”¯æ´è‡ªå‹•æ’éšŠ)")
    
    try:
        while running:
            try:
                data = stream.read(CHUNK, exception_on_overflow=False)
            except:
                break
            
            if not running:
                break
            
            # ä½¿ç”¨ VAD è™•ç†
            audio_data = vad.process(data)
            
            if audio_data is not None and len(audio_data) > CHUNK * 10:
                # å°‡èªéŸ³è³‡æ–™æ”¾å…¥ä½‡åˆ—ï¼Œè®“è¾¨è­˜åŸ·è¡Œç·’è™•ç†
                transcription_queue.put(audio_data)
                # ä¸è¦åœ¨é€™è£¡æ›´æ–° UI èªªã€Œè¾¨è­˜ä¸­ã€ï¼Œäº¤çµ¦æ¶ˆè²»è€…åŸ·è¡Œç·’è™•ç†ï¼Œ
                # é€™æ¨£æ‰èƒ½ç²¾ç¢ºåæ˜ ã€Œæ­£åœ¨è™•ç†ã€çš„ç‹€æ…‹ã€‚
                # ä½†å¦‚æœ Queue å¡è»Šåš´é‡ï¼Œæˆ‘å€‘å¯ä»¥åœ¨é€™è£¡é¡¯ç¤ºä¸€é»æç¤ºï¼ˆé¸æ“‡æ€§ï¼‰
    
    except Exception as e:
        if running:
            subtitle_window.update_text(f"éŒ¯èª¤: {str(e)}")
    
    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()


def signal_handler(signum, frame):
    """è™•ç† Ctrl+C ä¿¡è™Ÿ"""
    global running
    print("\n\næ­£åœ¨é—œé–‰...")
    running = False
    AppHelper.stopEventLoop()


def main():
    global running, model, task, language, vad_config, convert_tw
    
    parser = argparse.ArgumentParser(
        description="å³æ™‚å­—å¹•æµ®å‹•è¦–çª—ï¼ˆApple Silicon GPU åŠ é€Ÿï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # åŸºæœ¬ä½¿ç”¨
  uv run python subtitle/subtitle.py
  
  # ç¿»è­¯æˆè‹±æ–‡
  uv run python subtitle/subtitle.py --task translate
  
  # ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
  uv run python subtitle/subtitle.py --model mlx-community/whisper-medium-mlx
  
  # èª¿æ•´ VAD åƒæ•¸
  uv run python subtitle/subtitle.py --silence-duration 0.6
"""
    )
    parser.add_argument(
        "--model", "-m",
        type=str,
        default=None,
        help="æ¨¡å‹åç¨±ï¼šHF repo æˆ–æœ¬åœ°æ¨¡å‹åç¨±",
    )
    parser.add_argument(
        "--task", "-t",
        type=str,
        choices=["transcribe", "translate"],
        default="transcribe",
        help="ä»»å‹™ï¼štranscribeï¼ˆè½‰éŒ„ï¼‰æˆ– translateï¼ˆç¿»è­¯æˆè‹±æ–‡ï¼‰",
    )
    parser.add_argument(
        "--language", "-l",
        type=str,
        default=None,
        help="èªè¨€ä»£ç¢¼ï¼ˆå¦‚ zh, en, jaï¼‰",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹",
    )
    # VAD åƒæ•¸
    parser.add_argument(
        "--speech-threshold",
        type=float,
        default=0.5,
        help="èªéŸ³åµæ¸¬é–€æª»ï¼ˆ0.0~1.0ï¼‰ï¼Œè¶Šé«˜è¶Šåš´æ ¼ï¼Œé è¨­ 0.5",
    )
    parser.add_argument(
        "--silence-duration",
        type=float,
        default=0.6,
        help="èªéŸ³çµæŸå¾Œçš„éœéŸ³æ™‚é•·ï¼ˆç§’ï¼‰ï¼Œé è¨­ 0.6",
    )
    parser.add_argument(
        "--min-speech-duration",
        type=float,
        default=0.2,
        help="æœ€çŸ­èªéŸ³é•·åº¦ï¼ˆç§’ï¼‰ï¼Œå¤ªçŸ­æœƒè¢«å¿½ç•¥ï¼Œé è¨­ 0.2",
    )
    parser.add_argument(
        "--speech-pad-duration",
        type=float,
        default=0.1,
        help="èªéŸ³å‰å¾Œçš„ç·©è¡ï¼ˆç§’ï¼‰ï¼Œé è¨­ 0.1",
    )
    
    args = parser.parse_args()
    
    # åˆ—å‡ºæ¨¡å‹
    if args.list:
        local_models = list_local_models()
        print("æœ¬åœ°æ¨¡å‹:")
        if local_models:
            for m in local_models:
                print(f"  â€¢ {m}")
        else:
            print("  ï¼ˆç„¡ï¼‰")
        print()
        print("HuggingFace æ¨¡å‹:")
        print("  â€¢ mlx-community/whisper-large-v3-mlx")
        print("  â€¢ mlx-community/whisper-medium-mlx")
        print("  â€¢ mlx-community/whisper-small-mlx")
        return
    
    # è§£ææ¨¡å‹
    model = resolve_model(args.model)
    task = args.task
    language = args.language
    
    # åˆ¤æ–·æ˜¯å¦éœ€è¦è½‰æ›æˆè‡ºç£ç¹é«”
    convert_tw = should_convert_to_tw(model)
    
    # å»ºç«‹ VAD è¨­å®š
    vad_config = VADConfig(
        speech_threshold=args.speech_threshold,
        min_silence_duration=args.silence_duration,
        min_speech_duration=args.min_speech_duration,
        speech_pad_duration=args.speech_pad_duration,
        sample_rate=RATE,
    )
    
    # é¡¯ç¤ºè¨­å®š
    task_display = "è½‰éŒ„" if task == "transcribe" else "ç¿»è­¯æˆè‹±æ–‡"
    lang_display = language if language else "è‡ªå‹•åµæ¸¬"
    
    if "/" in model and not model.startswith("/"):
        model_display = model
    else:
        model_display = Path(model).name
    
    print("=" * 50)
    print("å³æ™‚å­—å¹•æµ®å‹•è¦–çª—")
    print("ä½¿ç”¨ Apple Silicon GPU åŠ é€Ÿ")
    print("=" * 50)
    print(f"æ¨¡å‹: {model_display}")
    print(f"ä»»å‹™: {task_display}")
    print(f"èªè¨€: {lang_display}")
    if convert_tw:
        print(f"ç°¡ç¹è½‰æ›: âœ“ è‡ºç£ç¹é«”")
    print("-" * 50)
    print("VAD è¨­å®š:")
    print(f"  èªéŸ³é–€æª»: {args.speech_threshold}")
    print(f"  éœéŸ³æ™‚é•·: {args.silence_duration} ç§’")
    print(f"  æœ€çŸ­èªéŸ³: {args.min_speech_duration} ç§’")
    print(f"  å‰å¾Œç·©è¡: {args.speech_pad_duration} ç§’")
    print("=" * 50)
    print(f"\nè¦–çª—è¨­å®šï¼š")
    print(f"  å¯¬åº¦ï¼šè¢å¹•çš„ {int(WINDOW_WIDTH_RATIO * 100)}%")
    print(f"  é¡¯ç¤ºè¡Œæ•¸ï¼š{MAX_LINES} è¡Œ")
    print(f"  å­—é«”ï¼š{FONT_SIZE} åƒç´ ")
    print(f"  é¡è‰²ï¼š{TEXT_COLOR}")
    print("\næ“ä½œèªªæ˜ï¼š")
    print("  â€¢ æ‹–å‹•å­—å¹•è¦–çª—å¯ç§»å‹•ä½ç½®")
    print("  â€¢ æŒ‰ Ctrl+C é—œé–‰ç¨‹å¼")
    print("  â€¢ å­—å¹•æœƒé¡¯ç¤ºåœ¨å…¨è¢å¹•ç°¡å ±ä¸Šæ–¹")
    print("  â€¢ æœ€æ–°çš„å­—å¹•æœƒåœ¨æœ€ä¸‹æ–¹")
    print("\næ­£åœ¨å•Ÿå‹•...\n")
    
    # è¨­å®šä¿¡è™Ÿè™•ç†
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # åˆå§‹åŒ–æ‡‰ç”¨ç¨‹å¼
    app = NSApplication.sharedApplication()
    app.setActivationPolicy_(NSApplicationActivationPolicyAccessory)
    
    # å»ºç«‹å­—å¹•è¦–çª—
    subtitle_window = SubtitleWindow()
    
    # å•Ÿå‹•éŒ„éŸ³åŸ·è¡Œç·’ (Capture)
    capture_t = threading.Thread(target=capture_thread, args=(subtitle_window,), daemon=True)
    capture_t.start()
    
    # å•Ÿå‹•è¾¨è­˜åŸ·è¡Œç·’ (Transcription)
    transcribe_t = threading.Thread(target=transcription_thread, args=(subtitle_window,), daemon=True)
    transcribe_t.start()
    
    # è¨­å®šå®šæ™‚å™¨ä¾†æª¢æŸ¥æ˜¯å¦éœ€è¦é—œé–‰
    def check_running():
        if not running:
            AppHelper.stopEventLoop()
        else:
            threading.Timer(0.5, lambda: AppHelper.callAfter(check_running)).start()
    
    AppHelper.callAfter(check_running)
    
    # åŸ·è¡Œä¸»è¿´åœˆ
    AppHelper.runEventLoop()
    
    print("å·²é—œé–‰")


if __name__ == "__main__":
    main()
