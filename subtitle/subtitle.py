"""
å³æ™‚å­—å¹•æµ®å‹•è¦–çª— - macOS åŸç”Ÿç‰ˆæœ¬
ä½¿ç”¨ PyObjC ç¢ºä¿åœ¨å…¨è¢å¹•ç°¡å ±ä¸Šæ–¹ä¹Ÿèƒ½é¡¯ç¤º

ä½¿ç”¨æ–¹å¼:
  # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆè‡ªå‹•åµæ¸¬ï¼‰
  uv run python subtitle.py
  
  # æŒ‡å®šæ¨¡å‹
  uv run python subtitle.py --model whisper-large-v2-taiwanese-hakka-v1-mlx
  
  # ç¿»è­¯æˆè‹±æ–‡
  uv run python subtitle.py --task translate
  
  # æŒ‡å®šèªè¨€
  uv run python subtitle.py --language zh
  
  # åˆ—å‡ºå¯ç”¨æ¨¡å‹
  uv run python subtitle.py --list
"""
import argparse
import signal
import sys
import threading
import numpy as np
import pyaudio
import mlx_whisper
from pathlib import Path

import AppKit
from AppKit import (
    NSApplication, NSWindow, NSTextField, NSColor, NSFont,
    NSWindowStyleMaskBorderless, NSBackingStoreBuffered,
    NSScreenSaverWindowLevel,
    NSMakeRect, NSScreen,
    NSTextAlignmentCenter,
    NSApplicationActivationPolicyAccessory
)
from PyObjCTools import AppHelper

# ===========================================
# ğŸ“ è¦–çª—è¨­å®šï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ===========================================
WINDOW_WIDTH_RATIO = 0.8      # è¦–çª—å¯¬åº¦ä½”è¢å¹•æ¯”ä¾‹ (0.0 ~ 1.0)
WINDOW_HEIGHT = 100           # è¦–çª—é«˜åº¦ (åƒç´ )
WINDOW_BOTTOM_MARGIN = 50     # è¦–çª—è·é›¢è¢å¹•åº•éƒ¨çš„è·é›¢ (åƒç´ )
WINDOW_OPACITY = 0.85         # è¦–çª—é€æ˜åº¦ (0.0 ~ 1.0ï¼Œ1.0 ç‚ºä¸é€æ˜)

# ===========================================
# ğŸ”¤ æ–‡å­—è¨­å®šï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ===========================================
FONT_SIZE = 48                # å­—é«”å¤§å° (åƒç´ )
FONT_NAME = None              # å­—é«”åç¨±ï¼ŒNone ç‚ºç³»çµ±é è¨­ç²—é«”

# ===========================================
# ğŸ¨ é¡è‰²è¨­å®šï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
# ===========================================
BACKGROUND_COLOR = (0.1, 0.1, 0.1)  # æ·±ç°è‰²
TEXT_COLOR = "white"          # white / yellow / green / cyan

# ===========================================
# ğŸ™ï¸ éŒ„éŸ³è¨­å®š
# ===========================================
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024
SILENCE_THRESHOLD = 500
SILENCE_DURATION = 1.2

# ===========================================
# è·¯å¾‘è¨­å®š
# ===========================================
SCRIPT_DIR = Path(__file__).parent
MODELS_DIR = SCRIPT_DIR.parent / "models"

# å…¨åŸŸè®Šæ•¸
running = True
model_path = None
task = "transcribe"
language = None


def list_available_models() -> list[str]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æœ¬åœ°æ¨¡å‹"""
    if not MODELS_DIR.exists():
        return []
    
    models = []
    for path in MODELS_DIR.iterdir():
        if path.is_dir():
            config_file = path / "config.json"
            weights_file = path / "weights.npz"
            if config_file.exists() and weights_file.exists():
                models.append(path.name)
    
    return sorted(models)


def get_model_path(model_name: str) -> Path:
    """å–å¾—æ¨¡å‹è·¯å¾‘"""
    if "/" in model_name or model_name.startswith("."):
        return Path(model_name)
    
    model_path = MODELS_DIR / model_name
    
    if not model_path.exists() and not model_name.endswith("-mlx"):
        model_path = MODELS_DIR / f"{model_name}-mlx"
    
    return model_path


def get_text_color():
    """å–å¾—æ–‡å­—é¡è‰²"""
    colors = {
        "white": NSColor.whiteColor(),
        "yellow": NSColor.yellowColor(),
        "green": NSColor.greenColor(),
        "cyan": NSColor.cyanColor(),
    }
    return colors.get(TEXT_COLOR, NSColor.whiteColor())


class SubtitleWindow:
    def __init__(self):
        screen = NSScreen.mainScreen()
        screen_frame = screen.frame()
        screen_width = screen_frame.size.width
        screen_height = screen_frame.size.height
        
        window_width = screen_width * WINDOW_WIDTH_RATIO
        window_height = WINDOW_HEIGHT
        x = (screen_width - window_width) / 2
        y = WINDOW_BOTTOM_MARGIN
        
        self.window = NSWindow.alloc().initWithContentRect_styleMask_backing_defer_(
            NSMakeRect(x, y, window_width, window_height),
            NSWindowStyleMaskBorderless,
            NSBackingStoreBuffered,
            False
        )
        
        self.window.setLevel_(NSScreenSaverWindowLevel)
        self.window.setOpaque_(False)
        self.window.setBackgroundColor_(
            NSColor.colorWithCalibratedRed_green_blue_alpha_(
                BACKGROUND_COLOR[0], 
                BACKGROUND_COLOR[1], 
                BACKGROUND_COLOR[2], 
                WINDOW_OPACITY
            )
        )
        self.window.setHasShadow_(True)
        self.window.setMovableByWindowBackground_(True)
        self.window.setCollectionBehavior_(
            AppKit.NSWindowCollectionBehaviorCanJoinAllSpaces |
            AppKit.NSWindowCollectionBehaviorFullScreenAuxiliary
        )
        
        content_view = self.window.contentView()
        self.label = NSTextField.alloc().initWithFrame_(
            NSMakeRect(20, 10, window_width - 40, window_height - 20)
        )
        self.label.setStringValue_("ğŸ¤ ç­‰å¾…èªªè©±...")
        
        if FONT_NAME:
            font = NSFont.fontWithName_size_(FONT_NAME, FONT_SIZE)
            if font is None:
                font = NSFont.boldSystemFontOfSize_(FONT_SIZE)
        else:
            font = NSFont.boldSystemFontOfSize_(FONT_SIZE)
        self.label.setFont_(font)
        
        self.label.setTextColor_(get_text_color())
        self.label.setBackgroundColor_(NSColor.clearColor())
        self.label.setBezeled_(False)
        self.label.setEditable_(False)
        self.label.setSelectable_(False)
        self.label.setAlignment_(NSTextAlignmentCenter)
        
        content_view.addSubview_(self.label)
        self.window.makeKeyAndOrderFront_(None)
    
    def update_text(self, text):
        """æ›´æ–°å­—å¹•æ–‡å­—ï¼ˆåŸ·è¡Œç·’å®‰å…¨ï¼‰"""
        def update():
            self.label.setStringValue_(text)
        AppHelper.callAfter(update)
    
    def close(self):
        def do_close():
            self.window.close()
            AppHelper.stopEventLoop()
        AppHelper.callAfter(do_close)


def get_audio_level(data):
    samples = np.frombuffer(data, dtype=np.int16)
    return np.abs(samples).mean()


def record_until_silence(stream):
    global running
    frames = []
    silent_chunks = 0
    chunks_for_silence = int(SILENCE_DURATION * RATE / CHUNK)
    is_speaking = False
    
    while running:
        try:
            data = stream.read(CHUNK, exception_on_overflow=False)
        except:
            break
        level = get_audio_level(data)
        
        if level > SILENCE_THRESHOLD:
            is_speaking = True
            silent_chunks = 0
            frames.append(data)
        elif is_speaking:
            frames.append(data)
            silent_chunks += 1
            if silent_chunks > chunks_for_silence:
                break
    
    return b''.join(frames)


def transcribe_audio(audio_data):
    global model_path, task, language
    
    audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
    
    kwargs = {
        "path_or_hf_repo": str(model_path),
        "task": task,
    }
    
    if language:
        kwargs["language"] = language
    
    result = mlx_whisper.transcribe(audio_np, **kwargs)
    
    return result["text"].strip()


def audio_thread(subtitle_window):
    """éŒ„éŸ³å’Œè¾¨è­˜çš„åŸ·è¡Œç·’"""
    global running, model_path, task, language
    
    audio = pyaudio.PyAudio()
    stream = audio.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK
    )
    
    subtitle_window.update_text("â³ è¼‰å…¥æ¨¡å‹ä¸­...")
    
    # é ç†±æ¨¡å‹
    dummy = np.zeros(RATE, dtype=np.float32)
    warmup_kwargs = {"path_or_hf_repo": str(model_path), "task": task}
    if language:
        warmup_kwargs["language"] = language
    mlx_whisper.transcribe(dummy, **warmup_kwargs)
    
    subtitle_window.update_text("ğŸ¤ æº–å‚™å°±ç·’ï¼Œé–‹å§‹èªªè©±...")
    
    try:
        while running:
            audio_data = record_until_silence(stream)
            
            if not running:
                break
            
            if len(audio_data) > CHUNK * 10:
                task_text = "ç¿»è­¯" if task == "translate" else "è¾¨è­˜"
                subtitle_window.update_text(f"â³ {task_text}ä¸­...")
                text = transcribe_audio(audio_data)
                if text and running:
                    subtitle_window.update_text(text)
    
    except Exception as e:
        if running:
            subtitle_window.update_text(f"éŒ¯èª¤: {str(e)}")
    
    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()


def signal_handler(signum, frame):
    """è™•ç† Ctrl+C ä¿¡è™Ÿ"""
    global running
    print("\n\næ­£åœ¨é—œé–‰...")
    running = False
    AppHelper.stopEventLoop()


def main():
    global running, model_path, task, language
    
    parser = argparse.ArgumentParser(
        description="å³æ™‚å­—å¹•æµ®å‹•è¦–çª—ï¼ˆä½¿ç”¨æœ¬åœ° MLX æ¨¡å‹ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # åŸºæœ¬ä½¿ç”¨ï¼ˆè‡ªå‹•åµæ¸¬èªè¨€ï¼Œç´”è½‰éŒ„ï¼‰
  uv run python subtitle.py
  
  # ç¿»è­¯æˆè‹±æ–‡
  uv run python subtitle.py --task translate
  
  # æŒ‡å®šèªè¨€ç‚ºä¸­æ–‡
  uv run python subtitle.py --language zh
  
  # ä½¿ç”¨ç‰¹å®šæ¨¡å‹
  uv run python subtitle.py --model whisper-large-v2-taiwanese-hakka-v1-mlx
"""
    )
    parser.add_argument(
        "--model", "-m",
        type=str,
        default=None,
        help="æ¨¡å‹åç¨±æˆ–è·¯å¾‘ï¼ˆé è¨­ï¼šä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„æœ¬åœ°æ¨¡å‹ï¼‰",
    )
    parser.add_argument(
        "--task", "-t",
        type=str,
        choices=["transcribe", "translate"],
        default="transcribe",
        help="ä»»å‹™é¡å‹ï¼štranscribeï¼ˆè½‰éŒ„ï¼‰æˆ– translateï¼ˆç¿»è­¯æˆè‹±æ–‡ï¼‰ï¼ˆé è¨­ï¼štranscribeï¼‰",
    )
    parser.add_argument(
        "--language", "-l",
        type=str,
        default=None,
        help="èªè¨€ä»£ç¢¼ï¼Œå¦‚ zh, en, jaï¼ˆé è¨­ï¼šè‡ªå‹•åµæ¸¬ï¼‰",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="åˆ—å‡ºå¯ç”¨çš„æœ¬åœ°æ¨¡å‹",
    )
    
    args = parser.parse_args()
    
    # åˆ—å‡ºæ¨¡å‹
    if args.list:
        models = list_available_models()
        if models:
            print("å¯ç”¨çš„æœ¬åœ°æ¨¡å‹:")
            for m in models:
                print(f"  â€¢ {m}")
        else:
            print("å°šæœªæœ‰è½‰æ›çš„æ¨¡å‹")
            print(f"\nè«‹å…ˆä½¿ç”¨ convert/convert.sh è½‰æ›æ¨¡å‹:")
            print(f"  cd ../convert")
            print(f"  ./convert.sh <hf-repo>")
        return
    
    # å–å¾—æ¨¡å‹
    available_models = list_available_models()
    
    if args.model:
        model_path = get_model_path(args.model)
    elif available_models:
        model_path = MODELS_DIR / available_models[0]
    else:
        print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ä»»ä½•æœ¬åœ°æ¨¡å‹")
        print(f"\nè«‹å…ˆè½‰æ›æ¨¡å‹:")
        print(f"  cd ../convert")
        print(f"  ./convert.sh <hf-repo>")
        sys.exit(1)
    
    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not model_path.exists():
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ¨¡å‹ {model_path}")
        if available_models:
            print(f"\nå¯ç”¨çš„æ¨¡å‹:")
            for m in available_models:
                print(f"  â€¢ {m}")
        sys.exit(1)
    
    # è¨­å®šå…¨åŸŸè®Šæ•¸
    task = args.task
    language = args.language
    
    # é¡¯ç¤ºè¨­å®š
    task_display = "è½‰éŒ„" if task == "transcribe" else "ç¿»è­¯æˆè‹±æ–‡"
    lang_display = language if language else "è‡ªå‹•åµæ¸¬"
    
    print("=" * 50)
    print("å³æ™‚å­—å¹•æµ®å‹•è¦–çª— (macOS åŸç”Ÿç‰ˆ)")
    print("ä½¿ç”¨ Apple Silicon GPU åŠ é€Ÿ")
    print("=" * 50)
    print(f"æ¨¡å‹: {model_path.name}")
    print(f"ä»»å‹™: {task_display}")
    print(f"èªè¨€: {lang_display}")
    print("=" * 50)
    print(f"\nè¦–çª—è¨­å®šï¼š")
    print(f"  å¯¬åº¦ï¼šè¢å¹•çš„ {int(WINDOW_WIDTH_RATIO * 100)}%")
    print(f"  é«˜åº¦ï¼š{WINDOW_HEIGHT} åƒç´ ")
    print(f"  å­—é«”ï¼š{FONT_SIZE} åƒç´ ")
    print(f"  é¡è‰²ï¼š{TEXT_COLOR}")
    print("\næ“ä½œèªªæ˜ï¼š")
    print("  â€¢ æ‹–å‹•å­—å¹•è¦–çª—å¯ç§»å‹•ä½ç½®")
    print("  â€¢ æŒ‰ Ctrl+C é—œé–‰ç¨‹å¼")
    print("  â€¢ å­—å¹•æœƒé¡¯ç¤ºåœ¨å…¨è¢å¹•ç°¡å ±ä¸Šæ–¹")
    print("\næ­£åœ¨å•Ÿå‹•...\n")
    
    # è¨­å®šä¿¡è™Ÿè™•ç†
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # åˆå§‹åŒ–æ‡‰ç”¨ç¨‹å¼
    app = NSApplication.sharedApplication()
    app.setActivationPolicy_(NSApplicationActivationPolicyAccessory)
    
    # å»ºç«‹å­—å¹•è¦–çª—
    subtitle_window = SubtitleWindow()
    
    # åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­åŸ·è¡ŒéŒ„éŸ³å’Œç¿»è­¯
    thread = threading.Thread(target=audio_thread, args=(subtitle_window,), daemon=True)
    thread.start()
    
    # è¨­å®šå®šæ™‚å™¨ä¾†æª¢æŸ¥æ˜¯å¦éœ€è¦é—œé–‰
    def check_running():
        if not running:
            AppHelper.stopEventLoop()
        else:
            threading.Timer(0.5, lambda: AppHelper.callAfter(check_running)).start()
    
    AppHelper.callAfter(check_running)
    
    # åŸ·è¡Œä¸»è¿´åœˆ
    AppHelper.runEventLoop()
    
    print("å·²é—œé–‰")


if __name__ == "__main__":
    main()
