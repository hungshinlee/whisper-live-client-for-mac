"""
MLX Whisper å³æ™‚èªéŸ³è½‰æ–‡å­—ï¼ˆä½¿ç”¨ Apple Silicon GPUï¼‰
ç´”è½‰éŒ„ç‰ˆæœ¬ï¼ˆä¸ç¿»è­¯ï¼‰
"""
import numpy as np
import pyaudio
import mlx_whisper

# æ¨¡å‹è¨­å®š - ä½¿ç”¨ MLX å„ªåŒ–ç‰ˆæœ¬
MODEL_NAME = "mlx-community/whisper-large-v3-turbo"

# éŒ„éŸ³è¨­å®š
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024
SILENCE_THRESHOLD = 500      # éœéŸ³é–€æª»
SILENCE_DURATION = 1.5       # éœéŸ³å¤šä¹…å¾Œé–‹å§‹è¾¨è­˜ï¼ˆç§’ï¼‰


def get_audio_level(data):
    """è¨ˆç®—éŸ³é‡"""
    samples = np.frombuffer(data, dtype=np.int16)
    return np.abs(samples).mean()


def record_until_silence(stream):
    """éŒ„éŸ³ç›´åˆ°éœéŸ³"""
    frames = []
    silent_chunks = 0
    chunks_for_silence = int(SILENCE_DURATION * RATE / CHUNK)
    is_speaking = False
    
    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        level = get_audio_level(data)
        
        if level > SILENCE_THRESHOLD:
            is_speaking = True
            silent_chunks = 0
            frames.append(data)
        elif is_speaking:
            frames.append(data)
            silent_chunks += 1
            if silent_chunks > chunks_for_silence:
                break
    
    return b''.join(frames)


def transcribe_audio(audio_data):
    """ä½¿ç”¨ MLX Whisper è¾¨è­˜"""
    # è½‰æ›ç‚º numpy array
    audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
    
    result = mlx_whisper.transcribe(
        audio_np,
        path_or_hf_repo=MODEL_NAME,
        language="zh",          # è¼¸å…¥èªè¨€ï¼šä¸­æ–‡
        task="transcribe",      # ç´”è½‰éŒ„ï¼ˆX->Xï¼Œä¿æŒåŸèªè¨€ï¼‰
    )
    
    return result["text"].strip()


def main():
    print("=" * 50)
    print("MLX Whisper å³æ™‚èªéŸ³è½‰æ–‡å­—")
    print("ä½¿ç”¨ Apple Silicon GPU åŠ é€Ÿ")
    print(f"æ¨¡å‹: {MODEL_NAME}")
    print("=" * 50)
    print("\nèªªè©±å¾Œæœƒé¡¯ç¤ºæ–‡å­—ï¼ˆä¿æŒåŸèªè¨€ï¼‰")
    print("æŒ‰ Ctrl+C åœæ­¢\n")
    print("-" * 50)
    
    # åˆå§‹åŒ– PyAudio
    audio = pyaudio.PyAudio()
    stream = audio.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK
    )
    
    print("æ­£åœ¨è¼‰å…¥æ¨¡å‹ï¼ˆé¦–æ¬¡éœ€è¦ä¸‹è¼‰ï¼Œç´„ 1.6GBï¼‰...")
    
    # é ç†±æ¨¡å‹
    dummy = np.zeros(RATE, dtype=np.float32)
    mlx_whisper.transcribe(dummy, path_or_hf_repo=MODEL_NAME)
    print("æ¨¡å‹è¼‰å…¥å®Œæˆï¼é–‹å§‹ç›£è½...\n")
    
    try:
        while True:
            print("ğŸ¤ ç­‰å¾…èªªè©±...", end="\r")
            audio_data = record_until_silence(stream)
            
            if len(audio_data) > CHUNK * 10:  # ç¢ºä¿æœ‰è¶³å¤ çš„éŸ³è¨Š
                print("â³ è¾¨è­˜ä¸­...   ", end="\r")
                text = transcribe_audio(audio_data)
                if text:
                    print(f"ğŸ“ {text}")
    
    except KeyboardInterrupt:
        print("\n\næ­£åœ¨é—œé–‰...")
    
    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()
        print("å·²åœæ­¢")


if __name__ == "__main__":
    main()
