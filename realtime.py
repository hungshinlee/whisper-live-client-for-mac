"""
MLX Whisper å³æ™‚èªéŸ³è¾¨è­˜ï¼ˆä½¿ç”¨ Apple Silicon GPUï¼‰

ä½¿ç”¨æ–¹å¼:
  # æœ€ç°¡å–®ï¼šä½¿ç”¨é è¨­ HF æ¨¡å‹
  uv run python realtime.py
  
  # ç¿»è­¯æˆè‹±æ–‡
  uv run python realtime.py --task translate
  
  # æŒ‡å®šèªè¨€
  uv run python realtime.py --language zh
  
  # ä½¿ç”¨ç‰¹å®š HF æ¨¡å‹
  uv run python realtime.py --model mlx-community/whisper-medium-mlx
  
  # ä½¿ç”¨æœ¬åœ°è½‰æ›çš„æ¨¡å‹
  uv run python realtime.py --model whisper-large-v2-taiwanese-hakka-v1-mlx
  
  # åˆ—å‡ºæœ¬åœ°æ¨¡å‹
  uv run python realtime.py --list
"""
import argparse
import sys
import numpy as np
import pyaudio
import mlx_whisper
from pathlib import Path

# ===========================================
# é è¨­è¨­å®š
# ===========================================
DEFAULT_HF_MODEL = "mlx-community/whisper-large-v3-mlx"
MODELS_DIR = Path(__file__).parent / "models"

# ===========================================
# éŒ„éŸ³è¨­å®š
# ===========================================
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024
SILENCE_THRESHOLD = 500
SILENCE_DURATION = 1.5


def list_local_models() -> list[str]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æœ¬åœ°æ¨¡å‹"""
    if not MODELS_DIR.exists():
        return []
    
    models = []
    for path in MODELS_DIR.iterdir():
        if path.is_dir():
            config_file = path / "config.json"
            weights_file = path / "weights.npz"
            if config_file.exists() and weights_file.exists():
                models.append(path.name)
    
    return sorted(models)


def resolve_model(model_name: str | None) -> str:
    """è§£ææ¨¡å‹åç¨±ï¼Œè¿”å›å¯ç”¨çš„æ¨¡å‹è·¯å¾‘æˆ– HF repo"""
    
    # å¦‚æœæ²’æœ‰æŒ‡å®šæ¨¡å‹
    if model_name is None:
        # å„ªå…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
        local_models = list_local_models()
        if local_models:
            model_path = MODELS_DIR / local_models[0]
            return str(model_path)
        # å¦å‰‡ä½¿ç”¨é è¨­ HF æ¨¡å‹
        return DEFAULT_HF_MODEL
    
    # å¦‚æœæ˜¯ HF repo æ ¼å¼ï¼ˆåŒ…å« /ï¼‰
    if "/" in model_name:
        return model_name
    
    # å˜—è©¦åœ¨æœ¬åœ° models ç›®éŒ„æ‰¾
    model_path = MODELS_DIR / model_name
    if model_path.exists():
        return str(model_path)
    
    # å˜—è©¦åŠ ä¸Š -mlx å¾Œç¶´
    if not model_name.endswith("-mlx"):
        model_path = MODELS_DIR / f"{model_name}-mlx"
        if model_path.exists():
            return str(model_path)
    
    # å‡è¨­æ˜¯ HF repo çš„ç°¡å¯«ï¼ˆå¦‚ whisper-large-v3-mlxï¼‰
    return f"mlx-community/{model_name}"


def get_audio_level(data):
    """è¨ˆç®—éŸ³é‡"""
    samples = np.frombuffer(data, dtype=np.int16)
    return np.abs(samples).mean()


def record_until_silence(stream):
    """éŒ„éŸ³ç›´åˆ°éœéŸ³"""
    frames = []
    silent_chunks = 0
    chunks_for_silence = int(SILENCE_DURATION * RATE / CHUNK)
    is_speaking = False
    
    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        level = get_audio_level(data)
        
        if level > SILENCE_THRESHOLD:
            is_speaking = True
            silent_chunks = 0
            frames.append(data)
        elif is_speaking:
            frames.append(data)
            silent_chunks += 1
            if silent_chunks > chunks_for_silence:
                break
    
    return b''.join(frames)


def transcribe_audio(audio_data, model: str, language: str | None, task: str):
    """ä½¿ç”¨ MLX Whisper è¾¨è­˜"""
    audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
    
    kwargs = {
        "path_or_hf_repo": model,
        "task": task,
    }
    
    if language:
        kwargs["language"] = language
    
    result = mlx_whisper.transcribe(audio_np, **kwargs)
    
    return result["text"].strip()


def main():
    parser = argparse.ArgumentParser(
        description="MLX Whisper å³æ™‚èªéŸ³è¾¨è­˜ï¼ˆApple Silicon GPU åŠ é€Ÿï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # æœ€ç°¡å–®ï¼šä½¿ç”¨é è¨­æ¨¡å‹ï¼Œè‡ªå‹•åµæ¸¬èªè¨€
  uv run python realtime.py
  
  # ç¿»è­¯æˆè‹±æ–‡
  uv run python realtime.py --task translate
  
  # æŒ‡å®šèªè¨€ç‚ºä¸­æ–‡
  uv run python realtime.py --language zh
  
  # ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼ˆé©åˆ M1/M2ï¼‰
  uv run python realtime.py --model mlx-community/whisper-medium-mlx
  
  # ä½¿ç”¨æœ¬åœ°è½‰æ›çš„æ¨¡å‹
  uv run python realtime.py --model whisper-large-v2-taiwanese-hakka-v1-mlx

å¸¸ç”¨æ¨¡å‹:
  mlx-community/whisper-large-v3-mlx    ~3GB   ç¿»è­¯âœ“  M3/M4 æ¨è–¦
  mlx-community/whisper-large-v3-turbo  ~1.6GB ç¿»è­¯âœ—  M2/M3/M4
  mlx-community/whisper-medium-mlx      ~1.5GB ç¿»è­¯âœ“  å…¨éƒ¨æ™¶ç‰‡
  mlx-community/whisper-small-mlx       ~488MB ç¿»è­¯âœ“  å…¨éƒ¨æ™¶ç‰‡
"""
    )
    parser.add_argument(
        "--model", "-m",
        type=str,
        default=None,
        help="æ¨¡å‹åç¨±ï¼šHF repoï¼ˆå¦‚ mlx-community/whisper-medium-mlxï¼‰æˆ–æœ¬åœ°æ¨¡å‹åç¨±",
    )
    parser.add_argument(
        "--task", "-t",
        type=str,
        choices=["transcribe", "translate"],
        default="transcribe",
        help="ä»»å‹™ï¼štranscribeï¼ˆè½‰éŒ„ï¼‰æˆ– translateï¼ˆç¿»è­¯æˆè‹±æ–‡ï¼‰",
    )
    parser.add_argument(
        "--language", "-l",
        type=str,
        default=None,
        help="èªè¨€ä»£ç¢¼ï¼ˆå¦‚ zh, en, jaï¼‰ï¼Œä¸æŒ‡å®šå‰‡è‡ªå‹•åµæ¸¬",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="åˆ—å‡ºå¯ç”¨çš„æœ¬åœ°æ¨¡å‹",
    )
    
    args = parser.parse_args()
    
    # åˆ—å‡ºæœ¬åœ°æ¨¡å‹
    if args.list:
        models = list_local_models()
        print("æœ¬åœ°æ¨¡å‹:")
        if models:
            for m in models:
                print(f"  â€¢ {m}")
        else:
            print("  ï¼ˆç„¡ï¼‰")
        print()
        print("HuggingFace æ¨¡å‹ï¼ˆæœƒè‡ªå‹•ä¸‹è¼‰ï¼‰:")
        print("  â€¢ mlx-community/whisper-large-v3-mlx")
        print("  â€¢ mlx-community/whisper-large-v3-turbo")
        print("  â€¢ mlx-community/whisper-medium-mlx")
        print("  â€¢ mlx-community/whisper-small-mlx")
        print("  â€¢ mlx-community/whisper-base-mlx")
        print("  â€¢ mlx-community/whisper-tiny-mlx")
        return
    
    # è§£ææ¨¡å‹
    model = resolve_model(args.model)
    
    # é¡¯ç¤ºè¨­å®š
    task_display = "è½‰éŒ„" if args.task == "transcribe" else "ç¿»è­¯æˆè‹±æ–‡"
    lang_display = args.language if args.language else "è‡ªå‹•åµæ¸¬"
    
    # åˆ¤æ–·æ¨¡å‹ä¾†æº
    if "/" in model and not model.startswith("/"):
        model_display = model  # HF repo
        model_source = "HuggingFace"
    else:
        model_display = Path(model).name  # æœ¬åœ°æ¨¡å‹
        model_source = "æœ¬åœ°"
    
    print("=" * 50)
    print("MLX Whisper å³æ™‚èªéŸ³è¾¨è­˜")
    print("ä½¿ç”¨ Apple Silicon GPU åŠ é€Ÿ")
    print("=" * 50)
    print(f"æ¨¡å‹: {model_display} ({model_source})")
    print(f"ä»»å‹™: {task_display}")
    print(f"èªè¨€: {lang_display}")
    print("=" * 50)
    print("\nèªªè©±å¾Œï¼Œæ–‡å­—æœƒå³æ™‚é¡¯ç¤º")
    print("æŒ‰ Ctrl+C åœæ­¢\n")
    print("-" * 50)
    
    # åˆå§‹åŒ– PyAudio
    audio = pyaudio.PyAudio()
    stream = audio.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK
    )
    
    print("æ­£åœ¨è¼‰å…¥æ¨¡å‹...")
    
    # é ç†±æ¨¡å‹
    dummy = np.zeros(RATE, dtype=np.float32)
    warmup_kwargs = {"path_or_hf_repo": model, "task": args.task}
    if args.language:
        warmup_kwargs["language"] = args.language
    mlx_whisper.transcribe(dummy, **warmup_kwargs)
    print("æ¨¡å‹è¼‰å…¥å®Œæˆï¼é–‹å§‹ç›£è½...\n")
    
    try:
        while True:
            print("ğŸ¤ ç­‰å¾…èªªè©±...", end="\r")
            audio_data = record_until_silence(stream)
            
            if len(audio_data) > CHUNK * 10:
                print("â³ è¾¨è­˜ä¸­...   ", end="\r")
                text = transcribe_audio(audio_data, model, args.language, args.task)
                if text:
                    print(f"ğŸ“ {text}")
    
    except KeyboardInterrupt:
        print("\n\næ­£åœ¨é—œé–‰...")
    
    finally:
        stream.stop_stream()
        stream.close()
        audio.terminate()
        print("å·²åœæ­¢")


if __name__ == "__main__":
    main()
